{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch Device GPU Setting\n",
    "- 작성일자: 2019.12.29\n",
    "- 작성자: MyungHoon Jin (github.com/jinmang2)\n",
    "- `ChatSpace` 모듈의 업데이트 시점에 따라 해당 내용이 바뀔 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JIT Compiled ChatSpace Model\n"
     ]
    }
   ],
   "source": [
    "# spacing\n",
    "from chatspace import ChatSpace\n",
    "\n",
    "# If you want to use gpu on torch, set parameter name 'device' as 'cuda'.\n",
    "spacer = ChatSpace(device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ['안녕안녕나는승배야',\n",
    "         '어허한두번이아니야경찰서가고싶어?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of backend CUDA but got backend CPU for argument #3 'index'\nThe above operation failed in interpreter, with the following stack trace:\nat code/model_jit.py:43:17\n  bias1 = _22.bias\n  _23 = self.batch_normalization\n  weight3 = _23.weight\n  bias2 = _23.bias\n  running_mean = _23.running_mean\n  running_var = _23.running_var\n  _24 = self.layer_normalization\n  weight4 = _24.weight\n  bias3 = _24.bias\n  embed_input = torch.embedding(weight, input, -1, False, False)\n                ~~~~~~~~~~~~~~~ <--- HERE\n  input0 = torch.transpose(embed_input, 1, 2)\n  input1 = torch._convolution(input0, _2, _3, [1], [0], [1], False, [0], 1, False, False, True)\n  input2 = torch.constant_pad_nd(input1, [1, 1], 0)\n  input3 = torch._convolution(input2, _5, _6, [1], [0], [1], False, [0], 1, False, False, True)\n  conv2_paded = torch.constant_pad_nd(input3, [3, 3], 0)\n  input4 = torch.cat([input2, conv2_paded], 1)\n  input5 = torch._convolution(input4, _8, _9, [1], [0], [1], False, [0], 1, False, False, True)\n  conv3_paded1 = torch.constant_pad_nd(input5, [2, 2], 0)\n  input6 = torch._convolution(input0, _8, _9, [1], [0], [1], False, [0], 1, False, False, True)\nThe above operation failed in interpreter, with the following stack trace:\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d90d5f601ddd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mspacer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\basic\\lib\\site-packages\\chatspace\\inference.py\u001b[0m in \u001b[0;36mspace\u001b[1;34m(self, texts, batch_size)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mbatch_texts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0moutput_text\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0moutput_text\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspace_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_texts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\basic\\lib\\site-packages\\chatspace\\inference.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mbatch_texts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0moutput_text\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0moutput_text\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspace_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_texts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\basic\\lib\\site-packages\\chatspace\\inference.py\u001b[0m in \u001b[0;36mspace_iter\u001b[1;34m(self, texts, batch_size)\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[0mbatch_texts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_single_batch_inference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_texts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_texts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\basic\\lib\\site-packages\\chatspace\\inference.py\u001b[0m in \u001b[0;36m_single_batch_inference\u001b[1;34m(self, batch, batch_texts)\u001b[0m\n\u001b[0;32m    104\u001b[0m         \"\"\"\n\u001b[0;32m    105\u001b[0m         \u001b[1;31m# model forward for chat-space nn.Module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"input\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"length\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;31m# make probability into class index with argmax\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected object of backend CUDA but got backend CPU for argument #3 'index'\nThe above operation failed in interpreter, with the following stack trace:\nat code/model_jit.py:43:17\n  bias1 = _22.bias\n  _23 = self.batch_normalization\n  weight3 = _23.weight\n  bias2 = _23.bias\n  running_mean = _23.running_mean\n  running_var = _23.running_var\n  _24 = self.layer_normalization\n  weight4 = _24.weight\n  bias3 = _24.bias\n  embed_input = torch.embedding(weight, input, -1, False, False)\n                ~~~~~~~~~~~~~~~ <--- HERE\n  input0 = torch.transpose(embed_input, 1, 2)\n  input1 = torch._convolution(input0, _2, _3, [1], [0], [1], False, [0], 1, False, False, True)\n  input2 = torch.constant_pad_nd(input1, [1, 1], 0)\n  input3 = torch._convolution(input2, _5, _6, [1], [0], [1], False, [0], 1, False, False, True)\n  conv2_paded = torch.constant_pad_nd(input3, [3, 3], 0)\n  input4 = torch.cat([input2, conv2_paded], 1)\n  input5 = torch._convolution(input4, _8, _9, [1], [0], [1], False, [0], 1, False, False, True)\n  conv3_paded1 = torch.constant_pad_nd(input5, [2, 2], 0)\n  input6 = torch._convolution(input0, _8, _9, [1], [0], [1], False, [0], 1, False, False, True)\nThe above operation failed in interpreter, with the following stack trace:\n"
     ]
    }
   ],
   "source": [
    "spacer.space(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JIT Compiled ChatSpace Model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['안녕 안녕 나는 승배야', '어허 한두번이 아니야 경찰서 가고 싶어?']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cpu에서는 잘 된다.\n",
    "spacer_cpu = ChatSpace(device='cpu')\n",
    "spacer_cpu.space(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 에러 발생 원인을 규명하고 교정하여 torch에서 gpu사용을 해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Go!\n",
    "우선 오류 내용을 보자. `space` 메서드를 사용하면 string일 경우 list로 만들어 batch_texts로 만들고 이를 기반으로 `spacer_iter` 메서드를 호출하여 batch마다 띄어쓰기를 검토한다. space 메서드는 아래와 같다.\n",
    "\n",
    "```python\n",
    "def space(self, texts: Union[List[str], str], batch_size: int = 64) -> Union[List[str], str]:\n",
    "    \"\"\"\n",
    "    띄어쓰기 하려는 문장을 넣으면, 띄어쓰기를 수정한 문장을 만들어 줘요!\n",
    "    전체 문장에 대한 inference가 끝나야 결과가 return 되기 때문에\n",
    "    띄어쓰기가 되는 순서대로 iterative 하게 사용하고 싶다면 space_iter함수를 하용하세요!\n",
    "\n",
    "    :param texts: 띄어쓰기를 하고자 하는 문장 또는 문장들\n",
    "    :param batch_size: 기본으로 64가 설정되어 있지만, 원하는 크기로 조정할 수 있음\n",
    "    :return: 띄어쓰기가 완료된 문장 또는 문장들\n",
    "    \"\"\"\n",
    "\n",
    "    batch_texts = [texts] if isinstance(texts, str) else texts\n",
    "    outputs = [output_text for output_text in self.space_iter(batch_texts, batch_size)]\n",
    "    return outputs if len(outputs) > 1 else outputs[0]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 `space_iter` 메서드를 살펴보자.\n",
    "\n",
    "우선 `data.ChatSpaeDataSet` 객체를 호출하고 이를 `torch.utils.data.DataLoader` 객체에 넣어준 후 `_single_batch_inference` 메서드를 활용하여 batch별 inference를 실시한다. `space_iter`의 코드는 아래와 같다.\n",
    "```python\n",
    "def space_iter(self, texts: List[str], batch_size: int = 64) -> Iterable[str]:\n",
    "    \"\"\"\n",
    "    띄어쓰기 하려는 문장을 넣으면, 띄어쓰기를 수정한 문장을 iterative 하게 만들어 줘요!\n",
    "    모든 띄어쓰기가 끝날 때 까지 기다리지 않아도 되니 for 문에서 사용할 수 있어요.\n",
    "\n",
    "    내부적으로는 띄어쓰기 하려는 문장(들)을 넣으면 dataset 으로 변환하고\n",
    "    model.forward에 넣을 수 있도록 token indexing 과 batching 작업을 진행합니다.\n",
    "\n",
    "    :param texts: 띄어쓰기를 하고자 하는 문장 또는 문장들\n",
    "    :param batch_size: 기본으로 64가 설정되어 있지만, 원하는 크기로 조정할 수 있음\n",
    "    :return: 띄어쓰기가 완료된 문장 또는 문장\n",
    "    :rtype collection.Iterable[str]\n",
    "    \"\"\"\n",
    "\n",
    "    dataset = ChatSpaceDataset(self.config, texts, self.vocab)\n",
    "    data_loader = DataLoader(dataset, batch_size, collate_fn=dataset.eval_collect_fn)\n",
    "\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        batch_texts = texts[i * batch_size : i * batch_size + batch_size]\n",
    "        for text in self._single_batch_inference(batch=batch, batch_texts=batch_texts):\n",
    "            yield text\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이를 불러오는 코드는 아래와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "# typing module, https://michigusa-nlp.tistory.com/3\n",
    "from typing import Dict, Generator, Iterable, List, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference.py의 다양한 객체 및 PATH 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./data/corpus/\n",
    "class DynamicCorpus:\n",
    "    def __init__(self, corpus_path, corpus_size=None, repeat=False):\n",
    "        self.corpus_path = corpus_path\n",
    "        self.corpus_file = self.open()\n",
    "        self.corpus_size = corpus_size if corpus_size else self._get_corpus_size()\n",
    "        self.line_pointer = 0\n",
    "        self.repeat = repeat\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        if self.line_pointer >= self.corpus_size:\n",
    "            if self.repeat:\n",
    "                self.reload()\n",
    "            else:\n",
    "                raise IndexError\n",
    "        return self.read_line()\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.reload()\n",
    "        for _ in range(self.corpus_size):\n",
    "            yield self.read_line()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.corpus_size\n",
    "\n",
    "    def read_line(self):\n",
    "        line = self.corpus_file.readline().strip()\n",
    "        self.line_pointer += 1\n",
    "        return line\n",
    "\n",
    "    def open(self):\n",
    "        self.corpus_file = open(self.corpus_path)\n",
    "        return self.corpus_file\n",
    "\n",
    "    def reload(self):\n",
    "        self.corpus_file.close()\n",
    "        self.open()\n",
    "        self.line_pointer = 0\n",
    "\n",
    "    def _get_corpus_size(self):\n",
    "        line_count = 0\n",
    "        for _ in self.corpus_file:\n",
    "            line_count += 1\n",
    "        self.reload()\n",
    "        return line_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import List, Union, Optional, Tuple\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_FORWARD_SPECIAL_TOKENS = (\"[PAD]\", \"[UNK]\", \"[SOS]\", \"[EOS]\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./vocab/Vocab\n",
    "class Vocab(dict):\n",
    "    def __init__(\n",
    "        self,\n",
    "        forward_special_tokens: Optional[\n",
    "            Union[List[str], Tuple[str, ...]]\n",
    "        ] = DEFAULT_FORWARD_SPECIAL_TOKENS,\n",
    "        tokens: Optional[Union[List[str], Tuple[str, ...]]] = None,\n",
    "        backward_special_tokens: Optional[Union[List[str], Tuple[str, ...]]] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        default forward special tokens will be allocated at forward index (0...4)\n",
    "        then tokens (list or tuple or iterable of str) will be allocated as next\n",
    "        at last, special_tokens will be allocated at last position.\n",
    "\n",
    "        :param tokens: list or tuple of tokens(str)\n",
    "        :param forward_special_tokens: tuple of string,\n",
    "                which indicate the special tokens appended in forward\n",
    "        :param backward_special_tokens: tuple of string,\n",
    "                which indicate the special tokens appended in backward\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.idx_to_token = []\n",
    "        self.forward_special_token = forward_special_tokens\n",
    "        self.tokens = tokens\n",
    "        self.backward_special_tokens = backward_special_tokens\n",
    "\n",
    "        # add special tokens on back size\n",
    "        if forward_special_tokens:\n",
    "            for special_token in forward_special_tokens:\n",
    "                self.add(special_token)\n",
    "\n",
    "        if tokens is not None:\n",
    "            for token in tokens:\n",
    "                self.add(token)\n",
    "\n",
    "        if backward_special_tokens is not None:\n",
    "            for special_token in backward_special_tokens:\n",
    "                self.add(special_token)\n",
    "\n",
    "    def add(self, token: str, index: int = None) -> int:\n",
    "        \"\"\"\n",
    "        add token on this vocab.\n",
    "\n",
    "        :param token: token which you want to add on this vocab\n",
    "        :param index: optional, index where you want to add.\n",
    "            if another token is exist in index, override it into this token.\n",
    "        :return: index of the token in vocab\n",
    "        \"\"\"\n",
    "        if token in self:\n",
    "            return self[int]\n",
    "\n",
    "        token_index = len(self) if index is None else index\n",
    "\n",
    "        if token_index == len(self) or token_index == 0:\n",
    "            self.idx_to_token.append(token)\n",
    "        else:\n",
    "            self.idx_to_token[token_index] = token\n",
    "\n",
    "        self[token] = token_index\n",
    "\n",
    "        return token_index\n",
    "\n",
    "    def build(\n",
    "        self,\n",
    "        lines: Union[Iterable, List[str]],\n",
    "        min_count: Optional[int] = None,\n",
    "        max_vocab_size: Optional[int] = None,\n",
    "        sep_token: str = \"\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        build vocab with multiple string lines.\n",
    "        vocab will be created as ascending order of token counter.\n",
    "        however index will be allocated after current fixed special tokens or others.\n",
    "\n",
    "        :param lines: texts or string iterable\n",
    "        :param min_count: optional, tokens need to be occurred then min_count\n",
    "        :param max_vocab_size: optional, vocab size will be limited with max_vocab_size\n",
    "        :param sep_token: line will be separated by sep_token (default: space)\n",
    "        :return: vocab instance\n",
    "        \"\"\"\n",
    "\n",
    "        counter = Counter()\n",
    "        for line in lines:\n",
    "            for token in line.strip().split(sep_token):\n",
    "                counter.update(token)\n",
    "\n",
    "        return self.build_with_counter(counter, min_count, max_vocab_size)\n",
    "\n",
    "    def build_with_counter(\n",
    "        self,\n",
    "        token_counter: Counter,\n",
    "        min_count: Optional[int] = None,\n",
    "        max_vocab_size: Optional[int] = None,\n",
    "    ) -> \"Vocab\":\n",
    "        \"\"\"\n",
    "        build vocab with token counter.\n",
    "        vocab will be created as ascending order of counter.\n",
    "        however index will be allocated after current fixed special tokens or others.\n",
    "\n",
    "        :param token_counter: counter class instance of token count\n",
    "        :param min_count: optional, tokens need to be occurred then min_count\n",
    "        :param max_vocab_size: optional, vocab size will be limited with max_vocab_size\n",
    "        :return vocab instance\n",
    "        \"\"\"\n",
    "\n",
    "        max_vocab_size = len(token_counter) if max_vocab_size is None else max_vocab_size\n",
    "        max_vocab_size -= len(self)\n",
    "\n",
    "        for token, count in token_counter.most_common(max_vocab_size):\n",
    "            if min_count is None or count >= min_count:\n",
    "                self.add(token)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def get_token(self, index: int) -> str:\n",
    "        \"\"\"\n",
    "        return token of given index.\n",
    "\n",
    "        :param index: query index to get the token\n",
    "        :return: token string\n",
    "        \"\"\"\n",
    "        return self.idx_to_token[index]\n",
    "\n",
    "    @staticmethod\n",
    "    def load(path: str, with_forward_special_tokens: bool = False) -> \"Vocab\":\n",
    "        \"\"\"\n",
    "        load vocab file from txt file.\n",
    "\n",
    "        :param path: vocab txt file path\n",
    "        :param with_forward_special_tokens:\n",
    "            if true, the forward special tokens(PAD, EOS ..) will be added\n",
    "            before txt vocab loading. and txt vocabs will be assigned in\n",
    "            backward position (e.x apple 4, banana 5 ...)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        with open(path) as f:\n",
    "            tokens = [line.strip() for line in f]\n",
    "\n",
    "        if with_forward_special_tokens:\n",
    "            return Vocab(tokens=tokens)\n",
    "        return Vocab(forward_special_tokens=None, tokens=tokens)\n",
    "\n",
    "    def dump(\n",
    "        self,\n",
    "        path: Optional[str] = None,\n",
    "        with_forward_special_tokens: bool = True,\n",
    "        with_backward_special_tokens: bool = True,\n",
    "    ) -> List[str]:\n",
    "        \"\"\"\n",
    "        dump and save vocab into file\n",
    "\n",
    "        :param path: path to save vocab\n",
    "        :param with_forward_special_tokens:\n",
    "            if true, dumped tokens include the forward_special_token\n",
    "        :param with_backward_special_tokens:\n",
    "            if true, dumped tokens include the backward_special_token\n",
    "        :return: dumped tokens as list of string\n",
    "        \"\"\"\n",
    "        dump_tokens = []\n",
    "\n",
    "        if with_forward_special_tokens and self.forward_special_token:\n",
    "            dump_tokens.extend(self.forward_special_token)\n",
    "\n",
    "        if self.tokens:\n",
    "            dump_tokens.extend(self.tokens)\n",
    "\n",
    "        if with_backward_special_tokens and self.backward_special_tokens:\n",
    "            dump_tokens.extend(self.backward_special_tokens)\n",
    "\n",
    "        if path is not None:\n",
    "            with open(path, \"w\") as f:\n",
    "                for token in dump_tokens:\n",
    "                    f.write(f\"{token}\\n\")\n",
    "\n",
    "        return dump_tokens\n",
    "\n",
    "    def keys(self):\n",
    "        return self.idx_to_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./indexer/Indexer\n",
    "class Indexer:\n",
    "    \"\"\"Indexer for word.\"\"\"\n",
    "\n",
    "    def __init__(self, vocab: Vocab):\n",
    "        \"\"\"\n",
    "        Init WordIndexer with inherited Indexer initializer\n",
    "\n",
    "        :param vocab: word vocab object\n",
    "        \"\"\"\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def encode(\n",
    "        self,\n",
    "        text: str,\n",
    "        max_seq_len: Optional[int] = None,\n",
    "        min_seq_len: Optional[int] = None,\n",
    "        pad_idx: int = 0,\n",
    "        unk_word: str = \"[UNK]\",\n",
    "    ) -> Union[List[int], str]:\n",
    "        \"\"\"\n",
    "        Convert tokenized tokens to corresponding ids.\n",
    "\n",
    "        When `max_seq_len` is not None, encoded tokens will be\n",
    "        padded up by padding idx to `max_seq_len`.\n",
    "\n",
    "        :param text: single text for encoding\n",
    "        :param min_seq_len: minimum sequence length of encoded tokens\n",
    "            if encoded tokens are shorter then min_seq_len add padding\n",
    "            tokens (min_seq_len - encoded_token_length) times.\n",
    "        :param max_seq_len : maximum sequence length of encoded tokens.\n",
    "            if encoded tokens are longer then max_seq_len then slice it.\n",
    "        :param pad_idx: padding token index(int) for padding\n",
    "        :param unk_word: get unk index with unk_word word as key\n",
    "        :return: list of token ids (int)\n",
    "        \"\"\"\n",
    "        unk_token_id = self.vocab.get(unk_word)\n",
    "        encoded_text = [self.vocab.get(token, unk_token_id) for token in text]\n",
    "        if min_seq_len is not None and len(encoded_text) < min_seq_len:\n",
    "            encoded_text.extend((pad_idx,) * (min_seq_len - len(encoded_text)))\n",
    "        if max_seq_len:\n",
    "            encoded_text = (\n",
    "                encoded_text if len(encoded_text) < max_seq_len else encoded_text[:max_seq_len]\n",
    "            )\n",
    "        return encoded_text\n",
    "\n",
    "    def decode(self, token_ids: Iterable[int], pad_idx: int = 0, as_str=False) -> List[str]:\n",
    "        \"\"\"\n",
    "        Convert token ids to corresponding tokens.\n",
    "\n",
    "        :param token_ids: token ids(list of int) for decoding\n",
    "        :param pad_idx: padding token index for padding\n",
    "        :param as_str: if true, return as concatenated string\n",
    "            if false, return as list of token string\n",
    "        :return: return decoded result. return type changed depends on as_str\n",
    "        \"\"\"\n",
    "        decoded_token_ids = [self.vocab.get_token(token_id) for token_id in token_ids]\n",
    "        return \"\".join(decoded_token_ids) if as_str else decoded_token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./dataset/ChatSpaceDataSet\n",
    "class ChatSpaceDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "        texts: Union[DynamicCorpus, List[str]],\n",
    "        vocab: Vocab,\n",
    "        with_random_space: bool = False,\n",
    "    ):\n",
    "        self.texts = texts\n",
    "        self.indexer = Indexer(vocab)\n",
    "        self.space_prob = config[\"space_prob\"]\n",
    "        self.with_random_space = with_random_space\n",
    "        self.config = config\n",
    "        self.lines = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.with_random_space:\n",
    "            model_input = self.get_train_input(self.texts[idx], idx)\n",
    "        else:\n",
    "            model_input = {\"input\": list(self.texts[idx])}\n",
    "\n",
    "        model_input[\"input\"] = self.indexer.encode(\n",
    "            model_input[\"input\"], min_seq_len=self.config[\"min_seq_len\"], unk_word=\"[UNK]\"\n",
    "        )\n",
    "        model_input[\"length\"] = len(model_input[\"input\"])\n",
    "        return model_input\n",
    "\n",
    "    def get_train_input(self, input_text, idx):\n",
    "        input_char, label = [], []\n",
    "        word_list = input_text.split()\n",
    "\n",
    "        for word in word_list:\n",
    "            word_label = [1] * (len(word) - 1) + [2]\n",
    "            char_list = list(word)\n",
    "\n",
    "            if random.random() < self.space_prob[idx % len(self.space_prob)]:\n",
    "                char_list.append(\" \")\n",
    "                word_label.append(1)\n",
    "\n",
    "            input_char.extend(char_list)\n",
    "            label.extend(word_label)\n",
    "\n",
    "        return {\"input\": \"\".join(input_char), \"label\": label}\n",
    "\n",
    "    @staticmethod\n",
    "    def train_collect_fn(batch):\n",
    "        max_seq_len = max([model_input[\"length\"] for model_input in batch])\n",
    "        for example in batch:\n",
    "            example[\"input\"].extend([0] * (max_seq_len - len(example[\"input\"])))\n",
    "            example[\"label\"].extend([0] * (max_seq_len - len(example[\"label\"])))\n",
    "\n",
    "        batch = {key: torch.tensor([example[key] for example in batch]) for key in batch[0].keys()}\n",
    "        return batch\n",
    "\n",
    "    @staticmethod\n",
    "    def eval_collect_fn(batch):\n",
    "        max_seq_len = max([model_input[\"length\"] for model_input in batch])\n",
    "        for example in batch:\n",
    "            example[\"input\"].extend([0] * (max_seq_len - len(example[\"input\"])))\n",
    "\n",
    "        batch = {key: torch.tensor([example[key] for example in batch]) for key in batch[0].keys()}\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ChatSpace` 객체를 호출하면 `__init__`에서 아래의 config과 vocab을 호출한다.\n",
    "\n",
    "현재는 각각의 객체를 전부 메모리에 올려서 어떤 값을 가지는지 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESOURCE_PATH = os.path.dirname(os.path.realpath(__file__))\n",
    "RESOURCE_PATH = 'C:/Users/jinma/Anaconda3/envs/basic/Lib/site-packages/chatspace/resource'\n",
    "\n",
    "VOCAB_PATH = os.path.join(RESOURCE_PATH, \"vocab.txt\")\n",
    "MODEL_DICT_PATH = os.path.join(RESOURCE_PATH, \"model/model.pt\")\n",
    "JIT_MODEL_PATH = os.path.join(RESOURCE_PATH, \"model/model_jit.pt\")\n",
    "CONFIG_PATH = os.path.join(RESOURCE_PATH, \"config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CONFIG_PATH) as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "with open(VOCAB_PATH, encoding='utf-8') as f:\n",
    "    vocab_tokens = [line.strip() for line in f]\n",
    "vocab = Vocab(tokens=vocab_tokens)\n",
    "config['vocab_size'] = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.001,\n",
       " 'batch_size': 512,\n",
       " 'valid_ratio': 0.025,\n",
       " 'epochs': 15,\n",
       " 'vocab_min_freq': 3,\n",
       " 'min_seq_len': 7,\n",
       " 'num_workers': 0,\n",
       " 'logging_step': 500,\n",
       " 'validation_step': 1500,\n",
       " 'test_threshold': 0.5,\n",
       " 'use_multi_gpu': False,\n",
       " 'device': 'cuda',\n",
       " 'embedding_dim': 256,\n",
       " 'cnn_filter': 3,\n",
       " 'cnn_features': 128,\n",
       " 'space_prob': [0, 0.15, 0.4],\n",
       " 'lstm_bidirectional': True,\n",
       " 'dropout_keep_prob': 0.1,\n",
       " 'apply_weight': False,\n",
       " 'lstm_layers': 1,\n",
       " 'vocab_size': 3563}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[PAD]': 0,\n",
       " '[UNK]': 1,\n",
       " '[SOS]': 2,\n",
       " '[EOS]': 3,\n",
       " ' ': 4,\n",
       " '<pad>': 5,\n",
       " '<unk>': 6,\n",
       " '<space>': 7,\n",
       " '.': 8,\n",
       " '이': 9,\n",
       " '어': 10,\n",
       " '아': 11,\n",
       " '?': 12,\n",
       " '다': 13,\n",
       " '나': 14,\n",
       " '가': 15,\n",
       " '그': 16,\n",
       " '요': 17,\n",
       " 'ㅋ': 18,\n",
       " '고': 19,\n",
       " '지': 20,\n",
       " '는': 21,\n",
       " '하': 22,\n",
       " '니': 23,\n",
       " '도': 24,\n",
       " '응': 25,\n",
       " 'ㅎ': 26,\n",
       " '자': 27,\n",
       " '거': 28,\n",
       " '해': 29,\n",
       " '에': 30,\n",
       " '야': 31,\n",
       " '게': 32,\n",
       " '서': 33,\n",
       " '안': 34,\n",
       " '오': 35,\n",
       " '데': 36,\n",
       " '기': 37,\n",
       " 'ㅠ': 38,\n",
       " '내': 39,\n",
       " '있': 40,\n",
       " '리': 41,\n",
       " '!': 42,\n",
       " '시': 43,\n",
       " '은': 44,\n",
       " '사': 45,\n",
       " '네': 46,\n",
       " '한': 47,\n",
       " '라': 48,\n",
       " '일': 49,\n",
       " '제': 50,\n",
       " '래': 51,\n",
       " '구': 52,\n",
       " '면': 53,\n",
       " '보': 54,\n",
       " ',': 55,\n",
       " '마': 56,\n",
       " '잘': 57,\n",
       " '을': 58,\n",
       " '만': 59,\n",
       " '너': 60,\n",
       " '까': 61,\n",
       " '먹': 62,\n",
       " '뭐': 63,\n",
       " '말': 64,\n",
       " '왜': 65,\n",
       " '난': 66,\n",
       " '들': 67,\n",
       " '로': 68,\n",
       " '무': 69,\n",
       " '으': 70,\n",
       " '웅': 71,\n",
       " '여': 72,\n",
       " '저': 73,\n",
       " '좀': 74,\n",
       " '우': 75,\n",
       " '금': 76,\n",
       " '수': 77,\n",
       " '대': 78,\n",
       " '없': 79,\n",
       " '좋': 80,\n",
       " '겠': 81,\n",
       " '주': 82,\n",
       " '진': 83,\n",
       " '러': 84,\n",
       " '와': 85,\n",
       " '더': 86,\n",
       " '했': 87,\n",
       " '할': 88,\n",
       " '정': 89,\n",
       " '같': 90,\n",
       " '알': 91,\n",
       " '집': 92,\n",
       " '려': 93,\n",
       " '음': 94,\n",
       " '전': 95,\n",
       " '인': 96,\n",
       " '럼': 97,\n",
       " '었': 98,\n",
       " 'N': 99,\n",
       " '장': 100,\n",
       " '근': 101,\n",
       " '늘': 102,\n",
       " '부': 103,\n",
       " '세': 104,\n",
       " '히': 105,\n",
       " '생': 106,\n",
       " '봐': 107,\n",
       " '냐': 108,\n",
       " '님': 109,\n",
       " '건': 110,\n",
       " '미': 111,\n",
       " '많': 112,\n",
       " '랑': 113,\n",
       " '신': 114,\n",
       " '~': 115,\n",
       " '왔': 116,\n",
       " '못': 117,\n",
       " '되': 118,\n",
       " '짜': 119,\n",
       " '간': 120,\n",
       " '때': 121,\n",
       " '바': 122,\n",
       " '예': 123,\n",
       " '모': 124,\n",
       " '두': 125,\n",
       " '빠': 126,\n",
       " '냥': 127,\n",
       " '의': 128,\n",
       " '런': 129,\n",
       " '비': 130,\n",
       " '렇': 131,\n",
       " '상': 132,\n",
       " '았': 133,\n",
       " '엄': 134,\n",
       " '또': 135,\n",
       " '를': 136,\n",
       " '씨': 137,\n",
       " '것': 138,\n",
       " '갈': 139,\n",
       " '밥': 140,\n",
       " '습': 141,\n",
       " '워': 142,\n",
       " '화': 143,\n",
       " '버': 144,\n",
       " '원': 145,\n",
       " '날': 146,\n",
       " '치': 147,\n",
       " '직': 148,\n",
       " '중': 149,\n",
       " '심': 150,\n",
       " '람': 151,\n",
       " '돼': 152,\n",
       " '머': 153,\n",
       " '애': 154,\n",
       " '스': 155,\n",
       " '소': 156,\n",
       " '드': 157,\n",
       " '당': 158,\n",
       " '디': 159,\n",
       " '방': 160,\n",
       " '죠': 161,\n",
       " '테': 162,\n",
       " '누': 163,\n",
       " '실': 164,\n",
       " '끝': 165,\n",
       " '얼': 166,\n",
       " '잠': 167,\n",
       " '조': 168,\n",
       " '분': 169,\n",
       " '번': 170,\n",
       " '싶': 171,\n",
       " '차': 172,\n",
       " '동': 173,\n",
       " '연': 174,\n",
       " '선': 175,\n",
       " '걸': 176,\n",
       " '맞': 177,\n",
       " '잖': 178,\n",
       " '살': 179,\n",
       " '남': 180,\n",
       " '영': 181,\n",
       " '언': 182,\n",
       " '각': 183,\n",
       " '른': 184,\n",
       " '줄': 185,\n",
       " '배': 186,\n",
       " '입': 187,\n",
       " '올': 188,\n",
       " '단': 189,\n",
       " '헤': 190,\n",
       " '르': 191,\n",
       " '혼': 192,\n",
       " '문': 193,\n",
       " '든': 194,\n",
       " '호': 195,\n",
       " '슨': 196,\n",
       " '회': 197,\n",
       " '속': 198,\n",
       " '계': 199,\n",
       " '식': 200,\n",
       " '재': 201,\n",
       " '않': 202,\n",
       " '피': 203,\n",
       " '물': 204,\n",
       " '긴': 205,\n",
       " '줘': 206,\n",
       " '유': 207,\n",
       " '따': 208,\n",
       " '빨': 209,\n",
       " '몰': 210,\n",
       " '-': 211,\n",
       " '준': 212,\n",
       " '파': 213,\n",
       " '괜': 214,\n",
       " '얘': 215,\n",
       " '찮': 216,\n",
       " '운': 217,\n",
       " '감': 218,\n",
       " '막': 219,\n",
       " '공': 220,\n",
       " '울': 221,\n",
       " '헐': 222,\n",
       " '친': 223,\n",
       " '받': 224,\n",
       " '개': 225,\n",
       " '씻': 226,\n",
       " '쉬': 227,\n",
       " '청': 228,\n",
       " '타': 229,\n",
       " '발': 230,\n",
       " '강': 231,\n",
       " '터': 232,\n",
       " '갔': 233,\n",
       " '학': 234,\n",
       " '힘': 235,\n",
       " '났': 236,\n",
       " '떻': 237,\n",
       " '노': 238,\n",
       " '셨': 239,\n",
       " '약': 240,\n",
       " '형': 241,\n",
       " '착': 242,\n",
       " '싫': 243,\n",
       " '맛': 244,\n",
       " '던': 245,\n",
       " '반': 246,\n",
       " '경': 247,\n",
       " '죽': 248,\n",
       " '찍': 249,\n",
       " '됐': 250,\n",
       " '써': 251,\n",
       " '참': 252,\n",
       " '술': 253,\n",
       " '과': 254,\n",
       " '눈': 255,\n",
       " '불': 256,\n",
       " '용': 257,\n",
       " 'ㅇ': 258,\n",
       " '볼': 259,\n",
       " '교': 260,\n",
       " '늦': 261,\n",
       " '결': 262,\n",
       " '달': 263,\n",
       " '출': 264,\n",
       " '행': 265,\n",
       " '후': 266,\n",
       " '국': 267,\n",
       " '열': 268,\n",
       " '넌': 269,\n",
       " '잉': 270,\n",
       " '쪽': 271,\n",
       " '졸': 272,\n",
       " '놀': 273,\n",
       " '길': 274,\n",
       " '겨': 275,\n",
       " '넘': 276,\n",
       " '성': 277,\n",
       " '민': 278,\n",
       " '잤': 279,\n",
       " '넹': 280,\n",
       " '새': 281,\n",
       " '돈': 282,\n",
       " '봤': 283,\n",
       " '처': 284,\n",
       " '적': 285,\n",
       " '점': 286,\n",
       " '별': 287,\n",
       " '작': 288,\n",
       " '께': 289,\n",
       " '온': 290,\n",
       " '위': 291,\n",
       " '뭘': 292,\n",
       " '낼': 293,\n",
       " '져': 294,\n",
       " '임': 295,\n",
       " '군': 296,\n",
       " '귀': 297,\n",
       " '키': 298,\n",
       " '허': 299,\n",
       " '프': 300,\n",
       " '곧': 301,\n",
       " '천': 302,\n",
       " '루': 303,\n",
       " '힝': 304,\n",
       " '명': 305,\n",
       " '손': 306,\n",
       " '뭔': 307,\n",
       " '편': 308,\n",
       " '셔': 309,\n",
       " '♥': 310,\n",
       " '김': 311,\n",
       " '트': 312,\n",
       " '합': 313,\n",
       " '꼭': 314,\n",
       " '듯': 315,\n",
       " '산': 316,\n",
       " '업': 317,\n",
       " '완': 318,\n",
       " '질': 319,\n",
       " '린': 320,\n",
       " '락': 321,\n",
       " '쓰': 322,\n",
       " '양': 323,\n",
       " '꺼': 324,\n",
       " '…': 325,\n",
       " '관': 326,\n",
       " 'ㅡ': 327,\n",
       " '깐': 328,\n",
       " '>': 329,\n",
       " '느': 330,\n",
       " '함': 331,\n",
       " '<': 332,\n",
       " '앞': 333,\n",
       " '벌': 334,\n",
       " '박': 335,\n",
       " '십': 336,\n",
       " '추': 337,\n",
       " '앙': 338,\n",
       " '본': 339,\n",
       " '현': 340,\n",
       " '태': 341,\n",
       " '먼': 342,\n",
       " '잔': 343,\n",
       " '설': 344,\n",
       " '찾': 345,\n",
       " '통': 346,\n",
       " '매': 347,\n",
       " '병': 348,\n",
       " '잡': 349,\n",
       " '월': 350,\n",
       " '엉': 351,\n",
       " '녀': 352,\n",
       " '침': 353,\n",
       " '담': 354,\n",
       " '된': 355,\n",
       " '딱': 356,\n",
       " '랬': 357,\n",
       " '휴': 358,\n",
       " '^': 359,\n",
       " '돌': 360,\n",
       " '글': 361,\n",
       " '꾸': 362,\n",
       " '크': 363,\n",
       " '싸': 364,\n",
       " '카': 365,\n",
       " '둘': 366,\n",
       " '몇': 367,\n",
       " '희': 368,\n",
       " '쁘': 369,\n",
       " '릴': 370,\n",
       " '놈': 371,\n",
       " '복': 372,\n",
       " 'M': 373,\n",
       " '목': 374,\n",
       " '렸': 375,\n",
       " '역': 376,\n",
       " '년': 377,\n",
       " '녁': 378,\n",
       " '럴': 379,\n",
       " '될': 380,\n",
       " '체': 381,\n",
       " '닌': 382,\n",
       " '절': 383,\n",
       " '갑': 384,\n",
       " '답': 385,\n",
       " '밖': 386,\n",
       " '밤': 387,\n",
       " '겁': 388,\n",
       " '흐': 389,\n",
       " '송': 390,\n",
       " '놓': 391,\n",
       " '름': 392,\n",
       " '망': 393,\n",
       " '엔': 394,\n",
       " '퇴': 395,\n",
       " '쳐': 396,\n",
       " '굴': 397,\n",
       " '녕': 398,\n",
       " '떡': 399,\n",
       " '곤': 400,\n",
       " '옷': 401,\n",
       " '몸': 402,\n",
       " '맘': 403,\n",
       " '티': 404,\n",
       " '웃': 405,\n",
       " '란': 406,\n",
       " '케': 407,\n",
       " 'ㄱ': 408,\n",
       " '끼': 409,\n",
       " '백': 410,\n",
       " '걱': 411,\n",
       " '푹': 412,\n",
       " '며': 413,\n",
       " '슬': 414,\n",
       " '커': 415,\n",
       " '걍': 416,\n",
       " '변': 417,\n",
       " '필': 418,\n",
       " '톡': 419,\n",
       " '증': 420,\n",
       " '석': 421,\n",
       " '철': 422,\n",
       " '삼': 423,\n",
       " '레': 424,\n",
       " '코': 425,\n",
       " '뻐': 426,\n",
       " '쁜': 427,\n",
       " '맨': 428,\n",
       " 'ㄷ': 429,\n",
       " '깨': 430,\n",
       " '짐': 431,\n",
       " '졌': 432,\n",
       " '순': 433,\n",
       " '책': 434,\n",
       " '짱': 435,\n",
       " '죄': 436,\n",
       " '흥': 437,\n",
       " '억': 438,\n",
       " '표': 439,\n",
       " '듣': 440,\n",
       " '였': 441,\n",
       " '떠': 442,\n",
       " '흠': 443,\n",
       " '림': 444,\n",
       " '외': 445,\n",
       " '혀': 446,\n",
       " '씀': 447,\n",
       " '옹': 448,\n",
       " 'U': 449,\n",
       " '칠': 450,\n",
       " '초': 451,\n",
       " '짓': 452,\n",
       " '토': 453,\n",
       " '확': 454,\n",
       " '❤': 455,\n",
       " '종': 456,\n",
       " '포': 457,\n",
       " '취': 458,\n",
       " '즘': 459,\n",
       " '큰': 460,\n",
       " '폰': 461,\n",
       " '팔': 462,\n",
       " '쯤': 463,\n",
       " ')': 464,\n",
       " '챙': 465,\n",
       " '급': 466,\n",
       " '앉': 467,\n",
       " '엥': 468,\n",
       " '멀': 469,\n",
       " '검': 470,\n",
       " '믿': 471,\n",
       " '험': 472,\n",
       " '최': 473,\n",
       " '꿈': 474,\n",
       " '풀': 475,\n",
       " '뽀': 476,\n",
       " '충': 477,\n",
       " '텐': 478,\n",
       " '켜': 479,\n",
       " 'ㄴ': 480,\n",
       " '혹': 481,\n",
       " '뒤': 482,\n",
       " '봉': 483,\n",
       " '탔': 484,\n",
       " '빼': 485,\n",
       " '왕': 486,\n",
       " '옴': 487,\n",
       " '력': 488,\n",
       " '움': 489,\n",
       " '꼬': 490,\n",
       " '쳤': 491,\n",
       " '웠': 492,\n",
       " '탁': 493,\n",
       " '럽': 494,\n",
       " '항': 495,\n",
       " '놔': 496,\n",
       " '춥': 497,\n",
       " '빵': 498,\n",
       " '윤': 499,\n",
       " '굿': 500,\n",
       " '헉': 501,\n",
       " '찬': 502,\n",
       " '암': 503,\n",
       " '악': 504,\n",
       " '평': 505,\n",
       " '메': 506,\n",
       " '쩌': 507,\n",
       " '등': 508,\n",
       " '떤': 509,\n",
       " '독': 510,\n",
       " '황': 511,\n",
       " '옆': 512,\n",
       " '법': 513,\n",
       " '찌': 514,\n",
       " '밀': 515,\n",
       " '떨': 516,\n",
       " '튼': 517,\n",
       " '격': 518,\n",
       " '접': 519,\n",
       " '똑': 520,\n",
       " '색': 521,\n",
       " '궁': 522,\n",
       " '투': 523,\n",
       " '료': 524,\n",
       " '갖': 525,\n",
       " '째': 526,\n",
       " '숙': 527,\n",
       " '승': 528,\n",
       " '숨': 529,\n",
       " '밌': 530,\n",
       " '넵': 531,\n",
       " '붙': 532,\n",
       " '널': 533,\n",
       " '섭': 534,\n",
       " '겼': 535,\n",
       " '혜': 536,\n",
       " '팅': 537,\n",
       " '랐': 538,\n",
       " '뇨': 539,\n",
       " '젠': 540,\n",
       " '골': 541,\n",
       " '줌': 542,\n",
       " '덥': 543,\n",
       " '(': 544,\n",
       " '판': 545,\n",
       " '흑': 546,\n",
       " '딸': 547,\n",
       " '퍼': 548,\n",
       " '쎄': 549,\n",
       " '쓸': 550,\n",
       " '론': 551,\n",
       " '왱': 552,\n",
       " '환': 553,\n",
       " '택': 554,\n",
       " '짝': 555,\n",
       " '욕': 556,\n",
       " '걔': 557,\n",
       " '록': 558,\n",
       " '능': 559,\n",
       " '1': 560,\n",
       " '뜻': 561,\n",
       " '쩔': 562,\n",
       " '봄': 563,\n",
       " '앗': 564,\n",
       " '끄': 565,\n",
       " '틀': 566,\n",
       " '맙': 567,\n",
       " '곳': 568,\n",
       " '창': 569,\n",
       " 'E': 570,\n",
       " '족': 571,\n",
       " '페': 572,\n",
       " '땡': 573,\n",
       " '줬': 574,\n",
       " '헿': 575,\n",
       " '0': 576,\n",
       " '멋': 577,\n",
       " '육': 578,\n",
       " '축': 579,\n",
       " '딴': 580,\n",
       " '쫌': 581,\n",
       " '땐': 582,\n",
       " '읽': 583,\n",
       " ';': 584,\n",
       " '냈': 585,\n",
       " '홍': 586,\n",
       " '끊': 587,\n",
       " '척': 588,\n",
       " '넣': 589,\n",
       " '큼': 590,\n",
       " '플': 591,\n",
       " '채': 592,\n",
       " '범': 593,\n",
       " '덕': 594,\n",
       " '맥': 595,\n",
       " '픈': 596,\n",
       " 'O': 597,\n",
       " '엽': 598,\n",
       " '끔': 599,\n",
       " '뜨': 600,\n",
       " '낮': 601,\n",
       " '탈': 602,\n",
       " '존': 603,\n",
       " '젤': 604,\n",
       " '빈': 605,\n",
       " '깼': 606,\n",
       " '품': 607,\n",
       " ':': 608,\n",
       " '킨': 609,\n",
       " '닙': 610,\n",
       " '쇼': 611,\n",
       " '징': 612,\n",
       " '특': 613,\n",
       " '팀': 614,\n",
       " '웬': 615,\n",
       " '패': 616,\n",
       " '쉽': 617,\n",
       " '씩': 618,\n",
       " '꿀': 619,\n",
       " '멍': 620,\n",
       " '풍': 621,\n",
       " '찰': 622,\n",
       " '덜': 623,\n",
       " '베': 624,\n",
       " '촌': 625,\n",
       " '낫': 626,\n",
       " '솔': 627,\n",
       " '샀': 628,\n",
       " '옥': 629,\n",
       " '향': 630,\n",
       " '즈': 631,\n",
       " '왠': 632,\n",
       " '2': 633,\n",
       " '꿔': 634,\n",
       " '얌': 635,\n",
       " '섯': 636,\n",
       " '랭': 637,\n",
       " '랜': 638,\n",
       " '낭': 639,\n",
       " '잊': 640,\n",
       " '닥': 641,\n",
       " 'ㅂ': 642,\n",
       " '됨': 643,\n",
       " '낌': 644,\n",
       " '꽃': 645,\n",
       " '뻔': 646,\n",
       " '벽': 647,\n",
       " '냄': 648,\n",
       " '훈': 649,\n",
       " '탕': 650,\n",
       " '잇': 651,\n",
       " '쟤': 652,\n",
       " '둬': 653,\n",
       " '뿐': 654,\n",
       " '첫': 655,\n",
       " '광': 656,\n",
       " '콜': 657,\n",
       " '딨': 658,\n",
       " '견': 659,\n",
       " '쟈': 660,\n",
       " '브': 661,\n",
       " '빡': 662,\n",
       " '핸': 663,\n",
       " '닝': 664,\n",
       " '류': 665,\n",
       " '퓨': 666,\n",
       " '립': 667,\n",
       " '빤': 668,\n",
       " '냠': 669,\n",
       " '똥': 670,\n",
       " '3': 671,\n",
       " '탄': 672,\n",
       " '빌': 673,\n",
       " '북': 674,\n",
       " '씬': 675,\n",
       " '맡': 676,\n",
       " '삐': 677,\n",
       " '딜': 678,\n",
       " '꼴': 679,\n",
       " '욱': 680,\n",
       " '쿠': 681,\n",
       " '낸': 682,\n",
       " '뛰': 683,\n",
       " '넴': 684,\n",
       " '권': 685,\n",
       " '효': 686,\n",
       " '총': 687,\n",
       " '뉴': 688,\n",
       " '춰': 689,\n",
       " '련': 690,\n",
       " '썼': 691,\n",
       " '샤': 692,\n",
       " '령': 693,\n",
       " '껴': 694,\n",
       " '닐': 695,\n",
       " '쪼': 696,\n",
       " '놨': 697,\n",
       " '땅': 698,\n",
       " '/': 699,\n",
       " '규': 700,\n",
       " '쪄': 701,\n",
       " '딩': 702,\n",
       " '뀨': 703,\n",
       " '곱': 704,\n",
       " '슴': 705,\n",
       " '묻': 706,\n",
       " '꽤': 707,\n",
       " '염': 708,\n",
       " '뿌': 709,\n",
       " '끌': 710,\n",
       " '컴': 711,\n",
       " '즐': 712,\n",
       " '굳': 713,\n",
       " '션': 714,\n",
       " '닮': 715,\n",
       " '깔': 716,\n",
       " '롱': 717,\n",
       " '깜': 718,\n",
       " '냉': 719,\n",
       " '쌍': 720,\n",
       " '농': 721,\n",
       " '잼': 722,\n",
       " 'ㅗ': 723,\n",
       " '극': 724,\n",
       " '5': 725,\n",
       " '익': 726,\n",
       " '닭': 727,\n",
       " '둥': 728,\n",
       " '핑': 729,\n",
       " '활': 730,\n",
       " '밑': 731,\n",
       " '쩐': 732,\n",
       " '텔': 733,\n",
       " '융': 734,\n",
       " '홀': 735,\n",
       " '첨': 736,\n",
       " '쉴': 737,\n",
       " '블': 738,\n",
       " 'ㅅ': 739,\n",
       " 'o': 740,\n",
       " '헛': 741,\n",
       " '획': 742,\n",
       " '됩': 743,\n",
       " '욜': 744,\n",
       " '압': 745,\n",
       " '땀': 746,\n",
       " '푸': 747,\n",
       " '논': 748,\n",
       " '쏘': 749,\n",
       " '클': 750,\n",
       " '폭': 751,\n",
       " '례': 752,\n",
       " '뽑': 753,\n",
       " 'e': 754,\n",
       " '칼': 755,\n",
       " '낳': 756,\n",
       " '땜': 757,\n",
       " '협': 758,\n",
       " '뿅': 759,\n",
       " '득': 760,\n",
       " '슈': 761,\n",
       " '렀': 762,\n",
       " '딘': 763,\n",
       " 'ㅤ': 764,\n",
       " '렵': 765,\n",
       " '콩': 766,\n",
       " '층': 767,\n",
       " '렁': 768,\n",
       " '쓴': 769,\n",
       " '떼': 770,\n",
       " '곡': 771,\n",
       " '롭': 772,\n",
       " '센': 773,\n",
       " '셋': 774,\n",
       " '옛': 775,\n",
       " '믄': 776,\n",
       " '콘': 777,\n",
       " '쥐': 778,\n",
       " '칭': 779,\n",
       " '링': 780,\n",
       " '껄': 781,\n",
       " '💕': 782,\n",
       " '낙': 783,\n",
       " '짧': 784,\n",
       " '헷': 785,\n",
       " '쌀': 786,\n",
       " '꺄': 787,\n",
       " '캐': 788,\n",
       " '싼': 789,\n",
       " '댁': 790,\n",
       " '탐': 791,\n",
       " '릇': 792,\n",
       " 'a': 793,\n",
       " '벗': 794,\n",
       " '켰': 795,\n",
       " '쭉': 796,\n",
       " '흘': 797,\n",
       " '흔': 798,\n",
       " '몬': 799,\n",
       " '쌤': 800,\n",
       " '괴': 801,\n",
       " '힣': 802,\n",
       " '털': 803,\n",
       " '쭈': 804,\n",
       " '쟁': 805,\n",
       " '뜩': 806,\n",
       " '잃': 807,\n",
       " '힌': 808,\n",
       " '엘': 809,\n",
       " '_': 810,\n",
       " '춘': 811,\n",
       " '끓': 812,\n",
       " '덩': 813,\n",
       " '랄': 814,\n",
       " '녹': 815,\n",
       " '볶': 816,\n",
       " '컨': 817,\n",
       " '짤': 818,\n",
       " '값': 819,\n",
       " '밝': 820,\n",
       " '높': 821,\n",
       " '쫓': 822,\n",
       " '량': 823,\n",
       " '훨': 824,\n",
       " 's': 825,\n",
       " '쥬': 826,\n",
       " '닦': 827,\n",
       " '밍': 828,\n",
       " '넷': 829,\n",
       " '납': 830,\n",
       " '큐': 831,\n",
       " '엇': 832,\n",
       " '4': 833,\n",
       " 't': 834,\n",
       " '쿤': 835,\n",
       " '킬': 836,\n",
       " '쿨': 837,\n",
       " '힐': 838,\n",
       " '꿨': 839,\n",
       " '쳇': 840,\n",
       " '샘': 841,\n",
       " '찜': 842,\n",
       " '깝': 843,\n",
       " '닫': 844,\n",
       " '묵': 845,\n",
       " '쨌': 846,\n",
       " '캬': 847,\n",
       " '걷': 848,\n",
       " '헌': 849,\n",
       " '옮': 850,\n",
       " '댜': 851,\n",
       " '댕': 852,\n",
       " 'ㅁ': 853,\n",
       " '쩡': 854,\n",
       " '뎅': 855,\n",
       " '혁': 856,\n",
       " '둔': 857,\n",
       " '뒷': 858,\n",
       " '헝': 859,\n",
       " '슷': 860,\n",
       " '혈': 861,\n",
       " '몽': 862,\n",
       " '얻': 863,\n",
       " '늙': 864,\n",
       " '놉': 865,\n",
       " '젊': 866,\n",
       " '짠': 867,\n",
       " '녜': 868,\n",
       " '햄': 869,\n",
       " '얍': 870,\n",
       " 'n': 871,\n",
       " '쉐': 872,\n",
       " '갚': 873,\n",
       " '액': 874,\n",
       " '윽': 875,\n",
       " 'A': 876,\n",
       " '껀': 877,\n",
       " '칫': 878,\n",
       " '팩': 879,\n",
       " '빙': 880,\n",
       " '겹': 881,\n",
       " '싹': 882,\n",
       " '뺏': 883,\n",
       " '렴': 884,\n",
       " 'i': 885,\n",
       " '띠': 886,\n",
       " '빛': 887,\n",
       " '뷰': 888,\n",
       " '봅': 889,\n",
       " '뵙': 890,\n",
       " '끗': 891,\n",
       " '뚝': 892,\n",
       " '뚜': 893,\n",
       " '뻥': 894,\n",
       " '훗': 895,\n",
       " '홉': 896,\n",
       " '턴': 897,\n",
       " '렌': 898,\n",
       " '겜': 899,\n",
       " '롤': 900,\n",
       " '힛': 901,\n",
       " '훔': 902,\n",
       " '꾼': 903,\n",
       " '갸': 904,\n",
       " '덮': 905,\n",
       " '팬': 906,\n",
       " '쁨': 907,\n",
       " 'ㅈ': 908,\n",
       " '곰': 909,\n",
       " '튀': 910,\n",
       " '춤': 911,\n",
       " '랴': 912,\n",
       " '촬': 913,\n",
       " '쵸': 914,\n",
       " '싱': 915,\n",
       " '뽕': 916,\n",
       " '뵈': 917,\n",
       " '햇': 918,\n",
       " '끈': 919,\n",
       " '맹': 920,\n",
       " '껏': 921,\n",
       " '욧': 922,\n",
       " '럭': 923,\n",
       " '긍': 924,\n",
       " '붕': 925,\n",
       " '혔': 926,\n",
       " '핫': 927,\n",
       " '듬': 928,\n",
       " '멘': 929,\n",
       " '념': 930,\n",
       " '객': 931,\n",
       " '뚱': 932,\n",
       " '쩜': 933,\n",
       " '9': 934,\n",
       " '멈': 935,\n",
       " '펴': 936,\n",
       " '헬': 937,\n",
       " 'd': 938,\n",
       " '썩': 939,\n",
       " '룹': 940,\n",
       " '랍': 941,\n",
       " '빴': 942,\n",
       " '탓': 943,\n",
       " '겸': 944,\n",
       " '슝': 945,\n",
       " '댔': 946,\n",
       " 'h': 947,\n",
       " '폐': 948,\n",
       " '앤': 949,\n",
       " '깡': 950,\n",
       " '흉': 951,\n",
       " '셈': 952,\n",
       " '츠': 953,\n",
       " '굶': 954,\n",
       " '6': 955,\n",
       " '룸': 956,\n",
       " '댓': 957,\n",
       " '눌': 958,\n",
       " '벼': 959,\n",
       " '깊': 960,\n",
       " '꽉': 961,\n",
       " '셤': 962,\n",
       " '‘': 963,\n",
       " '씹': 964,\n",
       " '팍': 965,\n",
       " '7': 966,\n",
       " '’': 967,\n",
       " '댄': 968,\n",
       " '킹': 969,\n",
       " '😊': 970,\n",
       " '델': 971,\n",
       " '덟': 972,\n",
       " '픔': 973,\n",
       " '뒀': 974,\n",
       " '찔': 975,\n",
       " '쌩': 976,\n",
       " '쁠': 977,\n",
       " '쌈': 978,\n",
       " '탱': 979,\n",
       " '웡': 980,\n",
       " '8': 981,\n",
       " 'r': 982,\n",
       " '율': 983,\n",
       " '릿': 984,\n",
       " '꽁': 985,\n",
       " '좌': 986,\n",
       " '쩍': 987,\n",
       " '갠': 988,\n",
       " '넓': 989,\n",
       " '쪙': 990,\n",
       " 'u': 991,\n",
       " '핵': 992,\n",
       " '틈': 993,\n",
       " '컷': 994,\n",
       " '흰': 995,\n",
       " '꼼': 996,\n",
       " '왓': 997,\n",
       " '턱': 998,\n",
       " '짬': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "device를 default인 cpu로 돌리면 잘 돌아간다.\n",
    "\n",
    "이 debugging의 목적은 gpu를 활용하여 speed-up하는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_device = torch.device('cuda:0')\n",
    "device = custom_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/jinma/Anaconda3/envs/basic/Lib/site-packages/chatspace/resource\\\\model/model_jit.pt'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# jit를 이용해서 모델 로딩이 가능한 pytorch 버전인지 체크\n",
    "# string으로 되어있는 torch versino을 비교할 수 있도록 int로 변환\n",
    "\n",
    "# 제 pc는 120이 나옵니다.\n",
    "from_jit = int(\"\".join(re.findall(r\"[0-9]+\", torch.__version__))) >= 110\n",
    "model_path = JIT_MODEL_PATH if from_jit else MODEL_DICT_PATH\n",
    "\n",
    "model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 model_path를 통해 model을 호출한다. 호출할 때 `from_jit`이 `True`이면 `_load_model_from_jit`을 사용하고 `RuntimeError`가 발생하면 `_load_model_from_dict`메서드를 활용하여 입력된 device 값을 사용한다. `from_jit`이 `False`이면 바로 `_load_model_from_dict`메서드로 활용한다. (아니, 이럴거면 왜 device를 입력받은거지? default는 True인데...) 코드는 아래와 같다.\n",
    "\n",
    "```python\n",
    "if from_jit:\n",
    "    try:\n",
    "        model = self._load_model_from_jit(model_path)\n",
    "    except RuntimeError:\n",
    "        print(\"Failed to load jit compiled model. Please set ChatSpace(as_jit=False)\")\n",
    "        model = self._load_model_from_dict(model_path, device)\n",
    "else:\n",
    "    model = self._load_model_from_dict(model_path, device)\n",
    "return model.to(device)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "바로 한번 호출해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아, 하기에 앞서 `ChatSpaceModel`을 호출해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./model/components/char_conv\n",
    "class CharConvolution(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=config[\"embedding_dim\"],\n",
    "            out_channels=config[\"cnn_features\"],\n",
    "            kernel_size=config[\"cnn_filter\"],\n",
    "        )\n",
    "        self.conv2 = nn.Conv1d(\n",
    "            in_channels=config[\"cnn_features\"],\n",
    "            out_channels=config[\"cnn_features\"],\n",
    "            kernel_size=config[\"cnn_filter\"] * 2 + 1,\n",
    "        )\n",
    "        self.conv3 = nn.Conv1d(\n",
    "            in_channels=config[\"cnn_features\"] * 2,\n",
    "            out_channels=config[\"cnn_features\"],\n",
    "            kernel_size=config[\"cnn_filter\"] * 2 - 1,\n",
    "        )\n",
    "\n",
    "        self.padding_1 = nn.ConstantPad1d(1, 0)\n",
    "        self.padding_2 = nn.ConstantPad1d(3, 0)\n",
    "        self.padding_3 = nn.ConstantPad1d(2, 0)\n",
    "\n",
    "    def forward(self, embed_input):\n",
    "        embed_input = torch.transpose(embed_input, dim0=1, dim1=2)\n",
    "        conv1_output = self.conv1(embed_input)\n",
    "        conv1_paded = self.padding_1(conv1_output)\n",
    "        conv2_output = self.conv2(conv1_paded)\n",
    "        conv2_paded = self.padding_2(conv2_output)\n",
    "        conv3_input = torch.cat((conv1_paded, conv2_paded), dim=1)\n",
    "        conv3_output1 = self.conv3(conv3_input)\n",
    "        conv3_paded1 = self.padding_3(conv3_output1)\n",
    "        conv3_output2 = self.conv3(embed_input)\n",
    "        conv3_paded2 = self.padding_3(conv3_output2)\n",
    "        return torch.cat((conv3_paded1, conv3_paded2, conv3_input), dim=1)\n",
    "    \n",
    "# ./model/components/char_lstm\n",
    "class CharLSTM(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=config[\"cnn_features\"] // 2,\n",
    "            hidden_size=config[\"cnn_features\"] // 2,\n",
    "            num_layers=config[\"lstm_layers\"],\n",
    "            bidirectional=config[\"lstm_bidirectional\"],\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "    def forward(self, x, length):\n",
    "        return self.lstm(x)[0]\n",
    "    \n",
    "# ./model/components/embed\n",
    "class CharEmbedding(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=config[\"vocab_size\"], embedding_dim=config[\"embedding_dim\"]\n",
    "        )\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        return self.embedding(input_seq)\n",
    "    \n",
    "# ./model/components/time_distributed\n",
    "class TimeDistributed(nn.Module):\n",
    "    def __init__(self, layer, activation=\"relu\"):\n",
    "        super().__init__()\n",
    "        self.layer = layer\n",
    "        self.activation = self.select_activation(activation)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_reshaped = x.contiguous().view(-1, x.size(-1))\n",
    "\n",
    "        y = self.layer(x_reshaped)\n",
    "        y = self.activation(y)\n",
    "\n",
    "        y = y.contiguous().view(x.size(0), -1, y.size(-1))\n",
    "        return y\n",
    "\n",
    "    def select_activation(self, activation):\n",
    "        if activation == \"relu\":\n",
    "            return nn.ReLU()\n",
    "        elif activation == \"sigmoid\":\n",
    "            return nn.Sigmoid()\n",
    "        elif activation == \"tanh\":\n",
    "            return nn.Tanh()\n",
    "        raise KeyError\n",
    "        \n",
    "# ./model/components/projection\n",
    "class Projection(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        # 0: PAD_TARGET, 1: NONE_SPACE_TARGET, 2: SPACE_TARGET\n",
    "        self.seq_fnn = TimeDistributed(nn.Linear(config[\"cnn_features\"], 3))\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # feed into projection layer\n",
    "        x = torch.transpose(x, 1, 0)\n",
    "        x = self.seq_fnn(x)\n",
    "\n",
    "        # log-softmax output\n",
    "        x = torch.transpose(x, 1, 0)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "# ./model/components/seq_fnn\n",
    "class SequentialFNN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.time_distributed_1 = TimeDistributed(\n",
    "            nn.Linear(in_features=config[\"cnn_features\"] * 4, out_features=config[\"cnn_features\"])\n",
    "        )\n",
    "        self.time_distributed_2 = TimeDistributed(\n",
    "            nn.Linear(in_features=config[\"cnn_features\"], out_features=config[\"cnn_features\"] // 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, conv_embed):\n",
    "        x = torch.transpose(conv_embed, 2, 1)\n",
    "        x = self.time_distributed_1(x)\n",
    "        x = self.time_distributed_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./model/model\n",
    "class ChatSpaceModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.embed = CharEmbedding(config)\n",
    "        self.conv = CharConvolution(config)\n",
    "        self.lstm = CharLSTM(config)\n",
    "        self.projection = Projection(config)\n",
    "        self.fnn = SequentialFNN(config)\n",
    "        self.batch_normalization = nn.BatchNorm1d(4 * config[\"cnn_features\"])\n",
    "        self.layer_normalization = nn.LayerNorm(config[\"cnn_features\"])\n",
    "\n",
    "    def forward(self, input_seq, length) -> torch.Tensor:\n",
    "        x = self.embed.forward(input_seq)\n",
    "        x = self.conv.forward(x)\n",
    "        x = self.batch_normalization.forward(x)\n",
    "        x = self.fnn.forward(x)\n",
    "        x = self.lstm.forward(x, length)\n",
    "        x = self.layer_normalization(x)\n",
    "        x = self.projection.forward(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JIT Compiled ChatSpace Model\n"
     ]
    }
   ],
   "source": [
    "# model 호출(from jit)\n",
    "# device = torch.device #  메서드의 기본값으로 실시해본다. <- 여기서 에러가 떴던것..\n",
    "print(\"Loading JIT Compiled ChatSpace Model\")\n",
    "model = torch.jit.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ScriptModule(\n",
       "  (embed): ScriptModule(\n",
       "    (embedding): ScriptModule()\n",
       "  )\n",
       "  (conv): ScriptModule(\n",
       "    (conv1): ScriptModule()\n",
       "    (conv2): ScriptModule()\n",
       "    (conv3): ScriptModule()\n",
       "    (padding_1): ScriptModule()\n",
       "    (padding_2): ScriptModule()\n",
       "    (padding_3): ScriptModule()\n",
       "  )\n",
       "  (lstm): ScriptModule(\n",
       "    (lstm): ScriptModule()\n",
       "  )\n",
       "  (projection): ScriptModule(\n",
       "    (seq_fnn): ScriptModule(\n",
       "      (layer): ScriptModule()\n",
       "      (activation): ScriptModule()\n",
       "    )\n",
       "    (softmax): ScriptModule()\n",
       "  )\n",
       "  (fnn): ScriptModule(\n",
       "    (time_distributed_1): ScriptModule(\n",
       "      (layer): ScriptModule()\n",
       "      (activation): ScriptModule()\n",
       "    )\n",
       "    (time_distributed_2): ScriptModule(\n",
       "      (layer): ScriptModule()\n",
       "      (activation): ScriptModule()\n",
       "    )\n",
       "  )\n",
       "  (batch_normalization): ScriptModule()\n",
       "  (layer_normalization): ScriptModule()\n",
       ")"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model # Union[torch.jit.ScriptModule, nn.Module]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "성공적으로 모델을 호출했다. 여기서 끝나는 것이 아니라 `__init__` 단계에서 `model.eval()`메서드를 호출하는 것이 마지막 단계이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ScriptModule(\n",
       "  (embed): ScriptModule(\n",
       "    (embedding): ScriptModule()\n",
       "  )\n",
       "  (conv): ScriptModule(\n",
       "    (conv1): ScriptModule()\n",
       "    (conv2): ScriptModule()\n",
       "    (conv3): ScriptModule()\n",
       "    (padding_1): ScriptModule()\n",
       "    (padding_2): ScriptModule()\n",
       "    (padding_3): ScriptModule()\n",
       "  )\n",
       "  (lstm): ScriptModule(\n",
       "    (lstm): ScriptModule()\n",
       "  )\n",
       "  (projection): ScriptModule(\n",
       "    (seq_fnn): ScriptModule(\n",
       "      (layer): ScriptModule()\n",
       "      (activation): ScriptModule()\n",
       "    )\n",
       "    (softmax): ScriptModule()\n",
       "  )\n",
       "  (fnn): ScriptModule(\n",
       "    (time_distributed_1): ScriptModule(\n",
       "      (layer): ScriptModule()\n",
       "      (activation): ScriptModule()\n",
       "    )\n",
       "    (time_distributed_2): ScriptModule(\n",
       "      (layer): ScriptModule()\n",
       "      (activation): ScriptModule()\n",
       "    )\n",
       "  )\n",
       "  (batch_normalization): ScriptModule()\n",
       "  (layer_normalization): ScriptModule()\n",
       ")"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "드디어 초기 작업이 끝났군... 이제 다시 `space` 메서드를 보자... 휴\n",
    "\n",
    "리마인드를 위해 `space`와 `space_iter` 메서드를 여기에 다시 기록한다.\n",
    "\n",
    "```python\n",
    "def space(self, texts: Union[List[str], str], batch_size: int = 64) -> Union[List[str], str]:\n",
    "    \"\"\"\n",
    "    띄어쓰기 하려는 문장을 넣으면, 띄어쓰기를 수정한 문장을 만들어 줘요!\n",
    "    전체 문장에 대한 inference가 끝나야 결과가 return 되기 때문에\n",
    "    띄어쓰기가 되는 순서대로 iterative 하게 사용하고 싶다면 space_iter함수를 하용하세요!\n",
    "\n",
    "    :param texts: 띄어쓰기를 하고자 하는 문장 또는 문장들\n",
    "    :param batch_size: 기본으로 64가 설정되어 있지만, 원하는 크기로 조정할 수 있음\n",
    "    :return: 띄어쓰기가 완료된 문장 또는 문장들\n",
    "    \"\"\"\n",
    "\n",
    "    batch_texts = [texts] if isinstance(texts, str) else texts\n",
    "    outputs = [output_text for output_text in self.space_iter(batch_texts, batch_size)]\n",
    "    return outputs if len(outputs) > 1 else outputs[0]\n",
    "\n",
    "def space_iter(self, texts: List[str], batch_size: int = 64) -> Iterable[str]:\n",
    "    \"\"\"\n",
    "    띄어쓰기 하려는 문장을 넣으면, 띄어쓰기를 수정한 문장을 iterative 하게 만들어 줘요!\n",
    "    모든 띄어쓰기가 끝날 때 까지 기다리지 않아도 되니 for 문에서 사용할 수 있어요.\n",
    "\n",
    "    내부적으로는 띄어쓰기 하려는 문장(들)을 넣으면 dataset 으로 변환하고\n",
    "    model.forward에 넣을 수 있도록 token indexing 과 batching 작업을 진행합니다.\n",
    "\n",
    "    :param texts: 띄어쓰기를 하고자 하는 문장 또는 문장들\n",
    "    :param batch_size: 기본으로 64가 설정되어 있지만, 원하는 크기로 조정할 수 있음\n",
    "    :return: 띄어쓰기가 완료된 문장 또는 문장\n",
    "    :rtype collection.Iterable[str]\n",
    "    \"\"\"\n",
    "\n",
    "    dataset = ChatSpaceDataset(self.config, texts, self.vocab)\n",
    "    data_loader = DataLoader(dataset, batch_size, collate_fn=dataset.eval_collect_fn)\n",
    "\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        batch_texts = texts[i * batch_size : i * batch_size + batch_size]\n",
    "        for text in self._single_batch_inference(batch=batch, batch_texts=batch_texts):\n",
    "            yield text\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지금은 list이기 때문에 무용지물\n",
    "batch_texts = [texts] if isinstance(texts, str) else texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# space_iter 메서드\n",
    "dataset = ChatSpaceDataset(config, batch_texts, vocab)\n",
    "data_loader = DataLoader(dataset, batch_size, collate_fn=dataset.eval_collect_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  {'input': tensor([[ 34, 398,  34, 398,  14,  21, 528, 186,  31,   0,   0,   0,   0,   0,\n",
       "              0,   0,   0],\n",
       "           [ 10, 299,  47, 125, 170,   9,  11,  23,  31, 247, 622,  33,  15,  19,\n",
       "            171,  10,  12]]),\n",
       "   'length': tensor([ 9, 17])})]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_iter = [(i, batch) for i, batch in enumerate(data_loader)]\n",
    "data_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " {'input': tensor([[ 34, 398,  34, 398,  14,  21, 528, 186,  31,   0,   0,   0,   0,   0,\n",
       "             0,   0,   0],\n",
       "          [ 10, 299,  47, 125, 170,   9,  11,  23,  31, 247, 622,  33,  15,  19,\n",
       "           171,  10,  12]]),\n",
       "  'length': tensor([ 9, 17])})"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i, batch = data_iter[0]\n",
    "i, batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['안녕안녕나는승배야', '어허한두번이아니야경찰서가고싶어?']"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_texts = batch_texts[i * batch_size : i * batch_size + batch_size]\n",
    "batch_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재는 2개의 text만 존재하여 전부 뽑혔지만 batch_size를 설정하기에 따라 한번에 처리할 text의 양이 변하는 구조이다.\n",
    "\n",
    "batch별 text에 대해 `_single_batch_inference` 메서드를 활용하여 inference를 수행하고 text를 return한다. 해당 메서드는 다음과 같다.\n",
    "\n",
    "```python\n",
    "def _single_batch_inference(\n",
    "    self, batch: Dict[str, torch.Tensor], batch_texts: List[str]\n",
    ") -> Generator[str, str, None]:\n",
    "    \"\"\"\n",
    "    batch input 을 모델에 넣고, 예측된 띄어쓰기를 원본 텍스트에 반영하여\n",
    "    띄어쓰기가 완료된 텍스트를 iterative 하게 생성 합니다!\n",
    "\n",
    "    :param batch: 'input', 'length' 두 키를 갖는 batch input\n",
    "        input은 char 를 encoding 한 [batch, seq_len] 크기의 torch.LongTensor\n",
    "        length는 각 sequence 의 길이 정보를 갖고 있는 [batch] 크기의 torch.LongTensor\n",
    "        length를 사용하는 이유는 dynamic LSTM을 사용하기 위해서 pack_padded_sequence 를 사용하기 때문임\n",
    "\n",
    "    :param batch_texts: batch 에 들어간 실제 원본 문장들\n",
    "    :return: 띄어쓰기가 완료된 문장\n",
    "    :rtype collection.Iterable[str]\n",
    "    \"\"\"\n",
    "    # model forward for chat-space nn.Module\n",
    "    output = self.model.forward(batch[\"input\"], batch[\"length\"])\n",
    "\n",
    "    # make probability into class index with argmax\n",
    "    space_preds = output.argmax(dim=-1).cpu().tolist()\n",
    "\n",
    "    for text, space_pred in zip(batch_texts, space_preds):\n",
    "        # yield generated text (spaced text)\n",
    "        yield self.generate_text(text, space_pred)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model forward for chat-space nn.Module\n",
    "output = model.forward(batch['input'], batch['length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2443e+01, -3.3778e-04, -8.0049e+00],\n",
       "         [-7.0465e+00, -2.5429e+00, -8.2852e-02],\n",
       "         [-1.1287e+01, -5.8670e-04, -7.4629e+00],\n",
       "         [-6.9063e+00, -2.9371e+00, -5.5537e-02],\n",
       "         [-1.0548e+01, -1.5441e-03, -6.4913e+00],\n",
       "         [-8.1212e+00, -5.0494e+00, -6.7329e-03],\n",
       "         [-9.5067e+00, -5.8422e-03, -5.1584e+00],\n",
       "         [-1.0821e+01, -1.5176e-03, -6.5046e+00],\n",
       "         [-1.2022e+01, -1.1197e+01, -1.9669e-05],\n",
       "         [ 0.0000e+00, -1.7328e+01, -1.7328e+01],\n",
       "         [ 0.0000e+00, -2.2758e+01, -2.2758e+01],\n",
       "         [ 0.0000e+00, -2.2310e+01, -2.2310e+01],\n",
       "         [ 0.0000e+00, -2.2295e+01, -2.2295e+01],\n",
       "         [ 0.0000e+00, -2.1146e+01, -2.1146e+01],\n",
       "         [ 0.0000e+00, -2.0427e+01, -2.0427e+01],\n",
       "         [ 0.0000e+00, -2.2574e+01, -2.2574e+01],\n",
       "         [ 0.0000e+00, -2.5446e+01, -2.5446e+01]],\n",
       "\n",
       "        [[-1.1313e+01, -1.0318e-03, -6.8889e+00],\n",
       "         [-8.2439e+00, -4.2906e+00, -1.4058e-02],\n",
       "         [-6.9846e+00, -2.2570e-01, -1.6039e+00],\n",
       "         [-6.8071e+00, -3.3294e-01, -1.2656e+00],\n",
       "         [-8.7215e+00, -1.2550e-02, -4.3974e+00],\n",
       "         [-7.6805e+00, -4.6243e+00, -1.0325e-02],\n",
       "         [-1.1122e+01, -4.6493e-04, -7.7060e+00],\n",
       "         [-1.1409e+01, -8.2447e-04, -7.1147e+00],\n",
       "         [-7.9561e+00, -4.0103e+00, -1.8652e-02],\n",
       "         [-9.6875e+00, -2.5560e-03, -5.9952e+00],\n",
       "         [-1.0936e+01, -6.4650e-04, -7.3721e+00],\n",
       "         [-7.4974e+00, -3.9827e+00, -1.9377e-02],\n",
       "         [-1.1330e+01, -1.1667e-03, -6.7645e+00],\n",
       "         [-7.8727e+00, -3.9782e+00, -1.9286e-02],\n",
       "         [-1.3560e+01, -1.2635e-04, -8.9869e+00],\n",
       "         [-9.6553e+00, -1.7888e-03, -6.3636e+00],\n",
       "         [-5.5242e+00, -4.6581e+00, -1.3565e-02]]],\n",
       "       grad_fn=<DifferentiableGraphBackward>)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "응? 여기서 이상한 method를 발견했다. 왜 cpu()를 사용할까..?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 1, 2, 1, 2, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2]]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space_preds = output.argmax(dim=-1).cpu().tolist()\n",
    "space_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('안녕안녕나는승배야', [1, 2, 1, 2, 1, 2, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " ('어허한두번이아니야경찰서가고싶어?', [1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2])]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = [(text, space_pred) for text, space_pred in zip(batch_texts, space_preds)]\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 다음엔 prediction된 class index를 `generate_text` 메서드를 활용, 실제 띄어쓰기로 generation한다. 코드는 아래와 같다.\n",
    "```python \n",
    "def generate_text(self, text: str, space_pred: List[int]) -> str:\n",
    "    \"\"\"\n",
    "    prediction 된 class index 를 실제 띄어쓰기로 generation 하는 부분\n",
    "\n",
    "    :param text: 띄어쓰기가 옳바르지 않은 원본 문장\n",
    "    :param space_pred: ChatSpaceModel.forward 에서 나온 결과를\n",
    "    argmax(dim=-1)한 [batch, seq_len] 크기의 3-class torch.LongTensor\n",
    "    0: PAD_TARGET, 1: NONE_SPACE_TARGET, 2: SPACE_TARGET\n",
    "    :return: 띄어쓰기가 반영된 문장\n",
    "    \"\"\"\n",
    "    generated_sentence = list()\n",
    "    for i in range(len(text)):\n",
    "        if space_pred[i] - 1 == 1:\n",
    "            generated_sentence.append(text[i] + \" \")\n",
    "        else:\n",
    "            generated_sentence.append(text[i])\n",
    "\n",
    "    joined_chars = \"\".join(generated_sentence)\n",
    "    return re.sub(r\" {2,}\", \" \", joined_chars).strip()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕안녕나는승배야\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['안', '녕 ', '안', '녕 ', '나', '는 ', '승', '배', '야 ']"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_sentence = list()\n",
    "text, space_pred = res[0]\n",
    "for i in range(len(text)):\n",
    "    if space_pred[i] - 1 == 1:\n",
    "        generated_sentence.append(text[i] + \" \")\n",
    "    else:\n",
    "        generated_sentence.append(text[i])\n",
    "print(text)\n",
    "generated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕 안녕 나는 승배야 '"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_chars = \"\".join(generated_sentence)\n",
    "joined_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕 안녕 나는 승배야'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\" {2,}\", \" \", joined_chars).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "???????????? 왜 직접 코드를 따라가니까 굉장히 잘되는거지...?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "에러가 발생한 부분은 `_single_batch_inference` 메서드에서 `forward`하는 부분이었다.\n",
    "\n",
    "지금 혹시 CPU로 돌리고 있나..?\n",
    "\n",
    "CPU로 돌리고 있는지 아닌지 다량의 데이터를 넣어 시간 체크를 해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = './data/' # 각자의 data path를 입력하도록 하자.\n",
    "df_train = pd.read_csv(data_path + 'train.csv')\n",
    "df_test = pd.read_csv(data_path + 'public_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year_month</th>\n",
       "      <th>text</th>\n",
       "      <th>smishing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>XXX은행성산XXX팀장입니다.행복한주말되세요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>오늘도많이웃으시는하루시작하세요XXX은행 진월동VIP라운지 XXX올림</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>안녕하십니까 고객님. XXX은행입니다.금일 납부하셔야 할 금액은 153600원 입니...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>XXX 고객님안녕하세요XXX은행 XXX지점입니다지난 한 해 동안 저희 XXX지점에 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>1월은 새로움이 가득XXX입니다.올 한해 더 많이행복한 한해되시길바랍니다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id year_month                                               text  smishing\n",
       "0   0    2017-01                           XXX은행성산XXX팀장입니다.행복한주말되세요         0\n",
       "1   1    2017-01              오늘도많이웃으시는하루시작하세요XXX은행 진월동VIP라운지 XXX올림         0\n",
       "2   2    2017-01  안녕하십니까 고객님. XXX은행입니다.금일 납부하셔야 할 금액은 153600원 입니...         0\n",
       "3   4    2017-01  XXX 고객님안녕하세요XXX은행 XXX지점입니다지난 한 해 동안 저희 XXX지점에 ...         0\n",
       "4   5    2017-01           1월은 새로움이 가득XXX입니다.올 한해 더 많이행복한 한해되시길바랍니다         0"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year_month</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>340000</td>\n",
       "      <td>2019-01</td>\n",
       "      <td>XXX고객님! 안녕하세요? 새롭게 시작하는 한 주 행복 가득하시길 기원합니다. 지난...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>340001</td>\n",
       "      <td>2019-01</td>\n",
       "      <td>긴급 안내  XXX은행 가락동 지점  - 헬리오XXX 기본XXX    대출이자를 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>340002</td>\n",
       "      <td>2019-01</td>\n",
       "      <td>XXX 고객님 안녕하세요올해는 미세먼지가 유난인거 같습니다.엊그제 새해가 시작된거같...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>340003</td>\n",
       "      <td>2019-01</td>\n",
       "      <td>XXX 고객님찾아온 행운을 잡으셨나요? 못잡으셨다면 이번에 다시 잡으시길 기원합니다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>340004</td>\n",
       "      <td>2019-01</td>\n",
       "      <td>XXX 고객님새해 복 많이 받으세요 XXX은행 코스트코 퇴직연금 담당자입니다.  고...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id year_month                                               text\n",
       "0  340000    2019-01  XXX고객님! 안녕하세요? 새롭게 시작하는 한 주 행복 가득하시길 기원합니다. 지난...\n",
       "1  340001    2019-01   긴급 안내  XXX은행 가락동 지점  - 헬리오XXX 기본XXX    대출이자를 ...\n",
       "2  340002    2019-01  XXX 고객님 안녕하세요올해는 미세먼지가 유난인거 같습니다.엊그제 새해가 시작된거같...\n",
       "3  340003    2019-01  XXX 고객님찾아온 행운을 잡으셨나요? 못잡으셨다면 이번에 다시 잡으시길 기원합니다...\n",
       "4  340004    2019-01  XXX 고객님새해 복 많이 받으세요 XXX은행 코스트코 퇴직연금 담당자입니다.  고..."
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_texts = df_train.loc[100:500, 'text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JIT Compiled ChatSpace Model\n"
     ]
    }
   ],
   "source": [
    "spacer_cpu = ChatSpace(device='cpu') # bench-mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatSpace_Mine:\n",
    "    \n",
    "    def __init__(self, config, vocab, device):\n",
    "        self.config = config\n",
    "        self.vocab = vocab\n",
    "        self.device = torch.device(device)\n",
    "\n",
    "        if model_path is None:\n",
    "            from_jit = self._is_jit_available() if from_jit else False\n",
    "            model_path = JIT_MODEL_PATH if from_jit else MODEL_DICT_PATH\n",
    "\n",
    "        self.model = self._load_model(model_path, self.device, from_jit=from_jit)\n",
    "        self.model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "basic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
