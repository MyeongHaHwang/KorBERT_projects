{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_20191230 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERT Config\n",
    "path = '../KorBERT/2_bert_download_002_bert_morp_tensorflow/002_bert_morp_tensorflow/'\n",
    "FLAGS.bert_config_file = path + 'bert_config.json'\n",
    "bert_config = BertConfig.from_json_file(FLAGS.bert_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     (FLAGS) MAX_SEQ_LENGTH           : 128\n",
      "(BERTConfig) MAX_POSITION_EMBEDDINGS  : 512\n"
     ]
    }
   ],
   "source": [
    "if FLAGS.max_seq_length > bert_config.max_position_embeddings:\n",
    "    raise ValueError(\n",
    "        \"Cannot use sequence length %d because the BERT model \"\n",
    "        \"was only trained up to sequence length %d\" %\n",
    "        (FLAGS.max_seq_length, bert_config.max_position_embeddings))\n",
    "else:\n",
    "    print('     (FLAGS) MAX_SEQ_LENGTH           :', FLAGS.max_seq_length)\n",
    "    print('(BERTConfig) MAX_POSITION_EMBEDDINGS  :', bert_config.max_position_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do not use TPU\n"
     ]
    }
   ],
   "source": [
    "# do not use tpu\n",
    "tpu_cluster_resolver = None\n",
    "if FLAGS.use_tpu and FLAGS.tpu_name:\n",
    "    tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(\n",
    "        FLAGS.tpu_name, zone=FLAGS.tpu_zone, project=FLAGS.gcp_project)\n",
    "else:\n",
    "    print('Do not use TPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "is_per_host = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2\n",
    "run_config = tf.contrib.tpu.RunConfig(\n",
    "    cluster=tpu_cluster_resolver,\n",
    "    master=FLAGS.master,\n",
    "    model_dir=FLAGS.output_dir,\n",
    "    save_checkpoints_steps=FLAGS.save_checkpoints_steps, # 1000\n",
    "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
    "        iterations_per_loop=FLAGS.iterations_per_loop, # 1000\n",
    "        num_shards=FLAGS.num_tpu_cores, # 8\n",
    "        per_host_input_for_training=is_per_host)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensorflow gpu 사용 가능한지 체크\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한국어 vocab 사전을 등록\n",
    "FLAGS.vocab_file = path + 'vocab.korean_morp.list' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dacon_path = '../dacon문자스미싱/filedown (2)/'\n",
    "df_train = pd.read_csv(dacon_path + 'train.csv')\n",
    "df_test = pd.read_csv(dacon_path + 'public_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((236756, 2), (59189, 2), (236756,), (59189,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train = df_train.set_index('id')\n",
    "df_test = df_test.set_index('id')\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "                 df_train[[col for col in df_train.columns if col != 'smishing']], \n",
    "                 df_train['smishing'],\n",
    "                 random_state=42, test_size=.2,\n",
    "                 stratify=df_train['smishing'])\n",
    "X_train.shape, X_valid.shape, y_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat((X_train, y_train), axis=1)\n",
    "df_valid = pd.concat((X_valid, y_valid), axis=1)\n",
    "\n",
    "# sample 100개씩 뽑아서 미리 test\n",
    "df_train.to_csv(dacon_path + 'train.tsv', sep='\\t')\n",
    "df_valid.to_csv(dacon_path + 'dev.tsv', sep='\\t')\n",
    "df_test.to_csv(dacon_path + 'test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataProcessor 제작\n",
    "class SmishingProcessor(DataProcessor):\n",
    "\n",
    "    def get_train_examples(self, data_dir, filename='train.tsv'):\n",
    "        return self._create_examples(\n",
    "            self._read_tsv(os.path.join(data_dir, filename)), \"train\")\n",
    "\n",
    "    def get_dev_examples(self, data_dir, filename='dev.tsv'):\n",
    "        return self._create_examples(\n",
    "            self._read_tsv(os.path.join(data_dir, filename)), \"dev\")\n",
    "\n",
    "    def get_test_examples(self, data_dir, filename='test.tsv'):\n",
    "        return self._create_examples(\n",
    "            self._read_tsv(os.path.join(data_dir, filename)), \"test\")\n",
    "\n",
    "    def get_labels(self):\n",
    "        return [\"0\", \"1\"]\n",
    "\n",
    "    def _create_examples(self, lines, set_type):\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            guid = \"%s-%s\" % (set_type, i)\n",
    "            text_a = convert_to_unicode(line[2])\n",
    "            if set_type == \"test\":\n",
    "                label = \"0\"\n",
    "            else:\n",
    "                label = convert_to_unicode(line[-1])\n",
    "            examples.append(\n",
    "                InputExample(guid=guid, text_a=text_a, label=label))\n",
    "        return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = SmishingProcessor()\n",
    "label_list = processor.get_labels()\n",
    "\n",
    "# get train samples\n",
    "train_examples = processor.get_train_examples(dacon_path, 'train.tsv')\n",
    "num_train_steps = int(\n",
    "    len(train_examples) / FLAGS.train_batch_size * FLAGS.num_train_epochs)\n",
    "num_warmup_steps = int(num_train_steps * FLAGS.warmup_proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record ETRI model weights\n",
    "FLAGS.init_checkpoint = path + 'model.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x000001B06F9DCB70>) includes params argument, but params are not passed to Estimator.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\jinma\\AppData\\Local\\Temp\\tmp984ihjm8\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\jinma\\\\AppData\\\\Local\\\\Temp\\\\tmp984ihjm8', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001B05F483D30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n",
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n"
     ]
    }
   ],
   "source": [
    "model_fn = model_fn_builder(\n",
    "    bert_config=bert_config,\n",
    "    num_labels=len(label_list),             # 2\n",
    "    init_checkpoint=FLAGS.init_checkpoint,  # None\n",
    "    learning_rate=FLAGS.learning_rate,      # 5e-05\n",
    "    num_train_steps=num_train_steps,        # 22195\n",
    "    num_warmup_steps=num_warmup_steps,      # 2219\n",
    "    use_tpu=FLAGS.use_tpu,                  # False\n",
    "    use_one_hot_embeddings=FLAGS.use_tpu)   # False\n",
    "\n",
    "# If TPU is not available, this will fall back to normal Estimator on CPU\n",
    "# or GPU\n",
    "estimator = tf.contrib.tpu.TPUEstimator(\n",
    "    use_tpu=FLAGS.use_tpu,                        # False\n",
    "    model_fn=model_fn,\n",
    "    config=run_config,\n",
    "    train_batch_size=FLAGS.train_batch_size,      # 32\n",
    "    eval_batch_size=FLAGS.eval_batch_size,        # 8\n",
    "    predict_batch_size=FLAGS.predict_batch_size   # 8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS.output_dir = './output_dir/smishing/'\n",
    "tf.gfile.MakeDirs(FLAGS.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = os.path.join(FLAGS.output_dir, 'train_nonspacing.tf_record')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "openapi_key = getpass(prompt='Password: ', stream=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BERTTokenizer(FLAGS.vocab_file, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\workspace\\projects\\utils_20191230.py:1369: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\workspace\\projects\\utils_20191230.py:1372: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:Writing example 0 of 236756\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: train-1\n",
      "INFO:tensorflow:tokens: [CLS] X X X/SL_ 고객/NNG_ 님/XSN_ ./SF_ X X X/SL_ [SEP]\n",
      "INFO:tensorflow:input_ids: 2 3047 3047 1496 1291 1123 7 3047 3047 1496 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: train-2\n",
      "INFO:tensorflow:tokens: [CLS] 녹음/NNG_ 이/VCP_ 짙 /EP_ 어/EC_ 가/VX_ 는/ETM_ 6/SN_ 월/NNB_ 2/SN_ 째/XSN_ 주 눈 부/NNG_ 신태 양/NNG_ 처럼/JKB_ 에너지/NNG_ 넘치/VV_ 는 /EF_ 출발/NNG_ 되/XSV_ 세요/EF_ !/SF_ X X X/SL_ 춘/NNG_ 의/JKG_ X X X/SL_ [SEP]\n",
      "INFO:tensorflow:input_ids: 2 4921 15 15453 8975 20 847 22 108 60 54 1908 321 3107 279 11378 771 434 2395 3494 2802 2213 2536 32 2103 524 3047 3047 1496 6347 13 3047 3047 1496 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: train-3\n",
      "INFO:tensorflow:tokens: [CLS] (/SS_ 광고/NNG_ )/SS_ 광고/NNG_ )/SS_ 광고/NNG_ )/SS_ X X X/SL_ 은행/NNG_ 제목/NNG_ :/SP_ (/SS_ 광고/NNG_ )/SS_ 나/NP_ 만/JX_ 모르/VV_ 았/EP_ 던/ETM_ 포인트/NNG_ 알뜰 히/MAG_ 챙기/VV_ 는/ETM_ 방법/NNG_ !/SF_ X X X/SL_ 금융/NNG_ 그룹/NNG_ 통합/NNG_ 멤 버 십/NNG_ Li iv/SL_ M ate/SL_ 에서/JKB_ 나/NP_ 의/JKG_ 포인트/NNG_ 확인/NNG_ 하/XSV_ 고/EC_ 은행/NNG_ 에서/JKB_ 이렇/VA_ 게/EC_ 활용/NNG_ 하/XSV_ 어/EC_ 보/VX_ 세요/EF_ !/SF_ 포인트/NNG_ 로/JKB_ X X X/SL_ 은행/NNG_ 수수/NNG_ 료/XSN_ 등/NNB_ 납부/NNG_ -/SS_ 포인트/NNG_ 로/JKB_ X X X/SL_ 은행/NNG_ 수수/NNG_ 료/XSN_ -/SS_ O T P/SL_ 발급/NNG_ 수수/NNG_ 료/XSN_ ./SF_ 대출/NNG_ 금/XSN_ ./SF_ 대출/NNG_ 이자/NNG_ -/SS_ 당/NNG_ ./SF_ 타 행/NNG_ 송금/NNG_ 수수/NNG_ 료/XSN_ 포인트/NNG_ 를/JKO_ AT M/SL_ 에서/JKB_ 바로/MAG_ 출 금/NNG_ (/SS_ 1/SN_ 만/NR_ 원/NNB_ 이상/NNG_ )/SS_ 가능/NNG_ 포인트/NNG_ 를/JKO_ 나/NP_ 의/JKG_ 계좌/NNG_ 로/JKB_ 입 금/NNG_ (/SS_ 1/SN_ 원/NNB_ 이상/NNG_ )/SS_ [SEP]\n",
      "INFO:tensorflow:input_ids: 2 29 1384 30 1384 30 1384 30 3047 3047 1496 994 2787 132 29 1384 30 191 98 679 43 68 1438 8262 759 2669 22 1160 524 3047 3047 1496 756 1031 1462 9673 640 3759 9400 13726 552 8623 27 191 13 1438 484 9 23 994 27 846 47 1492 9 20 281 2103 524 1438 31 3047 3047 1496 994 2691 1049 51 5928 95 1438 31 3047 3047 1496 994 2691 1049 95 872 794 1627 5092 2691 1049 7 1396 500 7 1396 3792 95 305 7 408 1321 10135 2691 1049 1438 19 8435 1555 27 1036 1667 644 29 50 85 86 237 30 226 1438 19 191 13 4170 31 1351 644 29 50 86 237 30 3\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: train-4\n",
      "INFO:tensorflow:tokens: [CLS] X X X/SL_ 고객/NNG_ 님/XSN_ 안녕/NNG_ 하/XSA_ 세요/EF_ ./SF_ 정기/NNG_ 예금/NNG_ 만기/NNG_ 경 과/NNG_ 로/JKB_ 안내/NNG_ 드리/XSV_ ㅂ니다/EF_ ./SF_ 내 점/NNG_ 이/JKS_ 어 /VA_ 려 우 신 경우/NNG_ 본인/NNG_ 핸드/NNG_ 폰/NNG_ 인증/NNG_ 을/JKO_ 통하/VV_ 어/EC_ 창구/NNG_ 에/JKB_ 내 점/NNG_ 하/XSV_ 지/EC_ 않/VX_ 고/EC_ 간 편하/VA_ 게/EC_ 재/XPN_ 예 치/NNG_ 하/XSV_ 는/ETM_ 방법/NNG_ 있/VA_ 어/EC_ 문자/NNG_ 보내/VV_ 어/EC_ 드리/VX_ ㅂ니다/EF_ ./SF_ 궁금 /VA_ 한/MM_ 점/NNB_ 있/VA_ 으시/EP_ 면/EC_ 전/NNG_ X X X/SL_ 드리/VX_ ㅂ니다/EF_ ./SF_ 행복/NNG_ 하/XSA_ ㄴ/ETM_ 오후/NNG_ 시간/NNG_ 되/XSV_ 세요/EF_ ./SF_ 전화/NNG_ X X X/SL_ -/SS_ X X X/SL_ -/SS_ X X X/SL_ 은행/NNG_ X X X/SL_ 올림/NNG_ [SEP]\n",
      "INFO:tensorflow:input_ids: 2 3047 3047 1496 1291 1123 4968 42 2103 7 3883 4803 8227 380 678 31 3879 4448 158 7 522 187 16 297 729 2100 288 291 183 1958 9465 339 3989 11 148 20 9529 14 522 187 9 48 59 23 763 3766 47 650 597 568 9 22 1160 38 20 2376 561 20 4971 158 7 14478 729 92 851 38 4506 71 135 3047 3047 1496 4971 158 7 2056 42 10 429 175 32 2103 7 823 3047 3047 1496 95 3047 3047 1496 95 3047 3047 1496 994 3047 3047 1496 11878 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: train-5\n",
      "INFO:tensorflow:tokens: [CLS] 한 주의/NNG_ 시작/NNG_ 월/NNG_ 요일/NNG_ 멋지/VA_ 게/EC_ 시작/NNG_ 하/XSV_ 세요/EF_ ./SF_ X X X/SL_ 은행/NNG_ 화 정/NNG_ X X X/SL_ 올림/NNG_ [SEP]\n",
      "INFO:tensorflow:input_ids: 2 286 704 224 1399 1875 3982 47 224 9 2103 7 3047 3047 1496 994 540 453 3047 3047 1496 11878 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    }
   ],
   "source": [
    "file_based_convert_examples_to_features(train_examples,\n",
    "                                        label_list,\n",
    "                                        FLAGS.max_seq_length,\n",
    "                                        tokenizer,\n",
    "                                        openapi_key,\n",
    "                                        train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "basic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
